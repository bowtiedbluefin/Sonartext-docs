---
title: 'Create Transcription'
openapi: 'POST /v1/audio/transcriptions'
---

OpenAI-compatible audio transcription endpoint with multiple file source options and advanced transcription features.

## Key Features

<CardGroup cols={2}>
<Card title="Multiple File Sources" icon="upload">
  Direct upload, storage references, or S3/GCS URLs for flexible integration
</Card>

<Card title="Speaker Diarization" icon="users">
  Identify and separate different speakers in your audio automatically
</Card>

<Card title="Multiple Formats" icon="file-lines">
  Output as JSON, text, SRT, VTT, or other formats for any use case
</Card>

<Card title="Advanced Timestamps" icon="clock">
  Word-level or segment-level timestamps for precise audio alignment
</Card>

<Card title="Language Detection" icon="globe">
  Automatic language detection or specify from 100+ supported languages
</Card>

<Card title="High Accuracy" icon="badge-check">
  Powered by Whisper Large v3 model for industry-leading transcription quality
</Card>
</CardGroup>

## File Source Options

<Tabs>
<Tab title="Direct Upload">
**Most common method**: Upload file directly in the request body.

- Best for files under 150MB
- Immediate processing
- Simple implementation

```bash
curl -X POST 'https://api.sonartext.com/v1/audio/transcriptions' \
  -H 'Authorization: Bearer stx_live_your_api_key' \
  -F 'file=@audio.wav' \
  -F 'model=whisper-v3-large-turbo'
```
</Tab>

<Tab title="Storage Reference">
**For re-transcription**: Use `storage_key` from previous multipart upload.

- Reuse uploaded files with different parameters
- No re-upload needed
- Cost-effective for multiple transcriptions

```bash
curl -X POST 'https://api.sonartext.com/v1/audio/transcriptions' \
  -H 'Authorization: Bearer stx_live_your_api_key' \
  -H 'Content-Type: application/json' \
  -d '{
    "storage_bucket": "sonartext-uploads",
    "storage_key": "uploads/user123/1234567890-audio.wav",
    "model": "whisper-v3-large-turbo"
  }'
```
</Tab>

<Tab title="S3/GCS Presigned URL">
**For integrations**: Provide presigned URL for external storage.

- Integrate with your own S3/GCS buckets
- No file transfer through our API
- Great for large files in external storage

```bash
curl -X POST 'https://api.sonartext.com/v1/audio/transcriptions' \
  -H 'Authorization: Bearer stx_live_your_api_key' \
  -H 'Content-Type: application/json' \
  -d '{
    "download_url": "https://mybucket.s3.amazonaws.com/file.wav?X-Amz-Signature=...",
    "model": "whisper-v3-large-turbo"
  }'
```
</Tab>
</Tabs>

## Example Usage

<CodeGroup>
```javascript Direct Upload
async function transcribeFile(file, options = {}) {
  const formData = new FormData();
  formData.append('file', file);
  formData.append('model', options.model || 'whisper-1');
  
  if (options.language) {
    formData.append('language', options.language);
  }
  
  if (options.diarization) {
    formData.append('enable_diarization', 'true');
    if (options.minSpeakers) formData.append('min_speakers', options.minSpeakers);
    if (options.maxSpeakers) formData.append('max_speakers', options.maxSpeakers);
  }
  
  formData.append('response_format', options.format || 'verbose_json');
  formData.append('timestamp_granularities', JSON.stringify(options.granularity || ['segment']));

  const response = await fetch('/v1/audio/transcriptions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`
    },
    body: formData
  });

  if (!response.ok) {
    throw new Error(`Transcription failed: ${response.statusText}`);
  }

  return response.json();
}

// Usage
const result = await transcribeFile(audioFile, {
  language: 'en',
  format: 'verbose_json',
  diarization: true,
  minSpeakers: 2,
  maxSpeakers: 4,
  granularity: ['segment', 'word']
});
```

```python R2 Re-transcription
import requests

def retranscribe_from_r2(r2_key, api_key, **options):
    url = 'https://api.sonartext.com/v1/audio/transcriptions'
    
    payload = {
        'r2_bucket': 'sonartext-uploads',
        'r2_key': r2_key,
        'model': options.get('model', 'whisper-1'),
        'response_format': options.get('response_format', 'verbose_json'),
        'timestamp_granularities': options.get('timestamp_granularities', ['segment'])
    }
    
    if 'language' in options:
        payload['language'] = options['language']
    
    if options.get('enable_diarization'):
        payload['enable_diarization'] = True
        if 'min_speakers' in options:
            payload['min_speakers'] = options['min_speakers']
        if 'max_speakers' in options:
            payload['max_speakers'] = options['max_speakers']
    
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }
    
    response = requests.post(url, json=payload, headers=headers)
    
    if response.status_code == 200:
        return response.json()
    else:
        raise Exception(f"Transcription failed: {response.text}")

# Usage - re-transcribe with different settings
result = retranscribe_from_r2(
    r2_key='uploads/user123/1234567890-audio.wav',
    api_key='stx_live_your_api_key',
    response_format='srt',  # Different format
    enable_diarization=False  # Different settings
)
```

```curl S3 Presigned URL
curl -X POST 'https://api.sonartext.com/v1/audio/transcriptions' \
  -H 'Authorization: Bearer stx_live_your_api_key' \
  -H 'Content-Type: application/json' \
  -d '{
    "download_url": "https://mybucket.s3.amazonaws.com/meeting.wav?X-Amz-Algorithm=AWS4-HMAC-SHA256&...",
    "model": "whisper-1",
    "language": "en",
    "response_format": "verbose_json",
    "enable_diarization": true,
    "min_speakers": 2,
    "max_speakers": 5,
    "timestamp_granularities": ["segment", "word"]
  }'
```
</CodeGroup>

## Response Examples

<ResponseExample>
```json Verbose JSON (with Diarization)
{
  "text": "Welcome to today's meeting. Let's start with the quarterly review. Thank you, I have the numbers ready.",
  "segments": [
    {
      "id": 0,
      "start": 0.5,
      "end": 3.2,
      "text": "Welcome to today's meeting.",
      "speaker": "Speaker_1",
      "confidence": 0.95
    },
    {
      "id": 1,
      "start": 3.5,
      "end": 6.8,
      "text": "Let's start with the quarterly review.",
      "speaker": "Speaker_1", 
      "confidence": 0.92
    },
    {
      "id": 2,
      "start": 7.1,
      "end": 10.3,
      "text": "Thank you, I have the numbers ready.",
      "speaker": "Speaker_2",
      "confidence": 0.89
    }
  ],
  "words": [
    {
      "word": "Welcome",
      "start": 0.5,
      "end": 0.9,
      "confidence": 0.98,
      "speaker": "Speaker_1"
    },
    {
      "word": "to",
      "start": 0.9,
      "end": 1.1,
      "confidence": 0.99,
      "speaker": "Speaker_1"
    }
    // ... more words
  ],
  "language": "en",
  "duration": 10.3,
  "speakers": [
    {
      "id": "Speaker_1",
      "label": "Speaker 1",
      "segments": [0, 1]
    },
    {
      "id": "Speaker_2", 
      "label": "Speaker 2",
      "segments": [2]
    }
  ]
}
```
</ResponseExample>

<ResponseExample>
```srt SRT Format
1
00:00:00,500 --> 00:00:03,200
<v Speaker_1>Welcome to today's meeting.

2
00:00:03,500 --> 00:00:06,800
<v Speaker_1>Let's start with the quarterly review.

3
00:00:07,100 --> 00:00:10,300
<v Speaker_2>Thank you, I have the numbers ready.
```
</ResponseExample>

<ResponseExample>
```vtt WebVTT Format
WEBVTT

NOTE
Generated by Sonartext API

00:00:00.500 --> 00:00:03.200
<v Speaker_1>Welcome to today's meeting.

00:00:03.500 --> 00:00:06.800
<v Speaker_1>Let's start with the quarterly review.

00:00:07.100 --> 00:00:10.300
<v Speaker_2>Thank you, I have the numbers ready.
```
</ResponseExample>

## Re-transcription Workflow

<Steps>
<Step title="Initial Upload">
  Upload a large file using multipart upload and get the `r2Key`.
  
  ```javascript
  const uploadResult = await completeUpload(uploadId, parts);
  const r2Key = uploadResult.r2Key; // Save this!
  ```
</Step>

<Step title="First Transcription">
  The initial transcription starts automatically after upload completion.
  
  ```javascript
  const jobId = uploadResult.jobId;
  // Monitor job and get results...
  ```
</Step>

<Step title="Re-transcribe with Different Settings">
  Use the saved `r2Key` to transcribe the same file with different parameters.
  
  ```javascript
  // Re-transcribe as SRT subtitle format
  const srtResult = await fetch('/v1/audio/transcriptions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      r2_bucket: 'sonartext-uploads',
      r2_key: r2Key,
      response_format: 'srt',
      enable_diarization: true
    })
  });
  ```
</Step>
</Steps>

## Best Practices

<AccordionGroup>
<Accordion title="ðŸŽ¯ Choose the Right Method">
  - **Direct upload**: Files < 150MB, immediate processing needed
  - **R2 reference**: Re-transcribing uploaded files with different settings
  - **S3 URL**: Integration with external storage systems
</Accordion>

<Accordion title="ðŸ”Š Optimize for Your Audio">
  - **Language**: Specify language for better accuracy (auto-detection is good but not perfect)
  - **Diarization**: Enable only if you need speaker identification (adds processing time)
  - **Format**: Choose format based on your use case (JSON for apps, SRT/VTT for video players)
</Accordion>

<Accordion title="âš¡ Performance Tips">
  - **Word timestamps**: Only request if needed (increases response size)
  - **Streaming**: Responses stream in real-time for faster perceived performance
  - **Caching**: Cache results and use R2 re-transcription for different formats
</Accordion>

<Accordion title="ðŸ’° Cost Optimization">
  - **Re-use uploads**: Save `r2Key` from multipart uploads for multiple transcriptions
  - **Right-size diarization**: Use accurate speaker count ranges for better results
  - **Format selection**: Choose the most appropriate format to avoid unnecessary re-processing
</Accordion>
</AccordionGroup>

## Error Responses

<ResponseExample>
```json File Too Large (Direct Upload)
{
  "error": "file_too_large",
  "message": "File size exceeds maximum allowed for direct upload",
  "details": {
    "fileSize": 3221225472,
    "maxSize": 2147483648,
    "suggestion": "Use multipart upload for files larger than 2GB"
  }
}
```
</ResponseExample>

<ResponseExample>
```json R2 Object Not Found
{
  "error": "r2_object_not_found",
  "message": "Specified R2 object could not be found",
  "details": {
    "bucket": "sonartext-uploads",
    "key": "uploads/user123/nonexistent-file.wav"
  }
}
```
</ResponseExample>

<ResponseExample>
```json Insufficient Credits
{
  "error": "insufficient_credits",
  "message": "Insufficient credits to process this request",
  "balance": {
    "cents": 50,
    "dollars": 0.50,
    "formatted": "$0.50"
  },
  "cost": {
    "cents": 150,
    "dollars": 1.50,
    "formatted": "$1.50"
  },
  "estimatedDuration": 180
}
```
</ResponseExample>

<Card title="Monitor Jobs" icon="list-check" href="/api-reference/jobs/list">
  Learn how to track and manage your transcription jobs
</Card>
